from langchain.document_loaders import UnstructuredMarkdownLoader, UnstructuredEPubLoader, UnstructuredPDFLoader
from langchain.vectorstores import Chroma, Pinecone
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
import pinecone
import os

OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')
PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')
PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV')

pdfs = [

]

annual_reports = []
for pdf in pdfs:
    #loader = UnstructuredMarkdownLoader(pdf) MarkDownFromChatGpt
    loader = UnstructuredEPubLoader(pdf)
    # Load the PDF document
    document = loader.load()        
    # Add the loaded document to our list
    annual_reports.append(document)

text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)

chunked_annual_reports = []
for annual_report in annual_reports:
    # Chunk the annual_report
    texts = text_splitter.split_documents(annual_report)
    # Add the chunks to chunked_annual_reports, which is a list of lists
    chunked_annual_reports.append(texts)
    print(f"chunked_annual_report length: {len(texts)}")
#Everything above should be split into ingesting phase

embeddings = OpenAIEmbeddings(
                                openai_api_key=OPENAI_API_KEY,
                                )
# Initialize Pinecone
pinecone.init(
    api_key=PINECONE_API_KEY,
    environment=PINECONE_API_ENV
)
index_name = "esoteric"

# Upsert annual reports to Pinecone via LangChain.
# There's likely a better way to do this instead of Pinecone.from_texts()
for chunks in chunked_annual_reports:
    Pinecone.from_texts([chunk.page_content for chunk in chunks], embeddings, index_name=index_name) 